# Overview

This package is named as `text-generate`. Literally, I would try several methods to achieve this goal.

Preliminarily, three methods come to my mind:

1. Use GPT-2
2. Use ConvS2S
3. Use sentence encoder


# Task

There are several scenarios that `Text Generation` could be used.

Let's say autocompletion(or recommendation), `Kite` is known as a notable tool using AI/NLP techniques to enhance autocompletion skills. 

More, for machine writing, `OpenAI` have already released their remarkable result in Text Generation using very large `GPT-2`. 


# Dependencies

In this project, I would need some packages to perform the experiemnts.

1. huggingface/transformers
2. pytorch/fairseq

and 
```commandline
pytorch==1.2.0
```

